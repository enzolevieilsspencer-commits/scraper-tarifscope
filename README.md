# üè® Booking.com Scraper - Veille Concurrentielle

Syst√®me de scraping automatis√© pour surveiller les prix de 6 h√¥tels √† Saint-R√©my-de-Provence.

## üìÅ Architecture

- **Scraper 1** : R√©cup√©ration des infos h√¥tel (manuel, via API)
- **Scraper 2** : Surveillance des prix sur 30 jours (automatique, 2x/jour)

## üöÄ Installation

### Pr√©requis
- Python 3.10+
- pip

### Setup

```bash
# Cloner le projet
cd booking-scraper-project

# Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou : venv\Scripts\activate  # Windows

# Installer d√©pendances
pip install -r requirements.txt

# Installer Playwright browsers
playwright install chromium

# Configurer variables d'environnement
cp .env.example .env
# √âditer .env avec vos vraies valeurs
```

## ‚öôÔ∏è Configuration

√âditer le fichier `.env` :

```env
SUPABASE_URL=https://drkfyyyeebvjdzdaiyxf.supabase.co
SUPABASE_SERVICE_KEY=eyJhbGc...
ENVIRONMENT=development
```

## üéØ Utilisation

### Scraper 1 : Infos H√¥tel (API)

D√©marrer le serveur API :

```bash
python src/api/server.py
```

Endpoint : `POST http://localhost:8000/scrape-hotel`

Body :
```json
{
  "url": "https://www.booking.com/hotel/fr/..."
}
```

### Scraper 2 : Prix Automatique

Ex√©cution manuelle (test) :
```bash
python src/scheduler/run_price_scraper.py
```

Ex√©cution automatique (production) :
```bash
python src/scheduler/cron_jobs.py
```

## üìä Tables Supabase

### Table `hotels`
```sql
CREATE TABLE hotels (
  id TEXT PRIMARY KEY,
  name TEXT NOT NULL,
  location TEXT,
  address TEXT,
  url TEXT NOT NULL,
  stars INTEGER,
  "photoUrl" TEXT,
  "isClient" BOOLEAN DEFAULT FALSE,
  "isMonitored" BOOLEAN DEFAULT TRUE,
  "createdAt" TIMESTAMP DEFAULT NOW(),
  "updatedAt" TIMESTAMP DEFAULT NOW()
);
```

### Table `rate_snapshots`
```sql
CREATE TABLE rate_snapshots (
  id TEXT PRIMARY KEY,
  "hotelId" TEXT NOT NULL REFERENCES hotels(id),
  "dateCheckin" DATE NOT NULL,
  price FLOAT8,
  currency TEXT DEFAULT 'EUR',
  available BOOLEAN DEFAULT TRUE,
  "scrapedAt" TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_rate_snapshots_hotel_date 
ON rate_snapshots("hotelId", "dateCheckin", "scrapedAt");
```

### Table `scraper_logs` (optionnel)
```sql
CREATE TABLE scraper_logs (
  id TEXT PRIMARY KEY,
  status TEXT NOT NULL,
  "hotelId" TEXT,
  "snapshotsCreated" INTEGER,
  error TEXT,
  "startedAt" TIMESTAMP DEFAULT NOW(),
  "completedAt" TIMESTAMP
);
```

## üö¢ D√©ploiement sur Railway

1. Cr√©er compte sur [Railway](https://railway.app)
2. Connecter votre repo GitHub
3. Ajouter les variables d'environnement
4. Le service d√©marre automatiquement

### Variables d'env √† configurer sur Railway :
- `SUPABASE_URL`
- `SUPABASE_SERVICE_KEY`
- `ENVIRONMENT=production`

## üîí S√©curit√©

- ‚úÖ User-Agent rotation
- ‚úÖ D√©lais al√©atoires entre requ√™tes
- ‚úÖ Horaires d'ex√©cution randomis√©s
- ‚úÖ Playwright en mode stealth
- ‚úÖ Sessions s√©par√©es (3 h√¥tels matin, 3 h√¥tels apr√®s-midi)

## üìù Logs

Les logs sont √©crits dans :
- Console (stdout)
- Table `scraper_logs` (Supabase)

## üêõ Debug

```bash
# Test scraper infos
python -c "from src.scrapers.hotel_info_scraper import scrape_hotel_info; print(scrape_hotel_info('URL_BOOKING'))"

# Test scraper prix
python src/scheduler/run_price_scraper.py --test
```

## üìß Support

En cas de probl√®me, v√©rifier :
1. Les logs dans Railway/Console
2. La table `scraper_logs` dans Supabase
3. Que Playwright est bien install√©
4. Les variables d'environnement

---

**D√©velopp√© pour la veille concurrentielle h√¥teli√®re √† Saint-R√©my-de-Provence** üè®
