"""
API FastAPI pour dÃ©clencher manuellement le scraping d'infos hÃ´tel
Endpoint: POST /scrape-hotel avec {"url": "..."}
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, HttpUrl
from typing import Optional
import asyncio
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from scrapers.hotel_info_scraper import scrape_hotel_info
from database.supabase_client import supabase_client
from config import API_HOST, API_PORT

app = FastAPI(
    title="Booking Scraper API",
    description="API pour scraper les infos des hÃ´tels Booking.com",
    version="1.0.0"
)

# CORS pour permettre les appels depuis Next.js
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, spÃ©cifier les domaines autorisÃ©s
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ScrapeHotelRequest(BaseModel):
    """Request body pour scraper un hÃ´tel"""
    url: str
    isClient: Optional[bool] = False
    isMonitored: Optional[bool] = True


class ScrapeHotelResponse(BaseModel):
    """Response aprÃ¨s scraping"""
    success: bool
    message: str
    hotel: Optional[dict] = None
    error: Optional[str] = None


@app.get("/")
async def root():
    """Health check"""
    return {
        "status": "running",
        "service": "Booking Scraper API",
        "version": "1.0.0"
    }


@app.get("/health")
async def health():
    """Health check endpoint"""
    return {"status": "healthy"}


@app.post("/scrape-hotel", response_model=ScrapeHotelResponse)
async def scrape_hotel(request: ScrapeHotelRequest):
    """
    Scrape les informations d'un hÃ´tel Booking.com
    
    Body:
    {
        "url": "https://www.booking.com/hotel/fr/...",
        "isClient": false,
        "isMonitored": true
    }
    """
    try:
        print(f"\nğŸ” RequÃªte de scraping: {request.url}")
        
        # VÃ©rifier si l'hÃ´tel existe dÃ©jÃ 
        existing_hotel = supabase_client.get_hotel_by_url(request.url)
        if existing_hotel:
            return ScrapeHotelResponse(
                success=False,
                message="Cet hÃ´tel existe dÃ©jÃ  dans la base",
                hotel=existing_hotel,
                error="Hotel already exists"
            )
        
        # Scraper les infos
        hotel_data = scrape_hotel_info(request.url)
        
        if not hotel_data:
            raise HTTPException(
                status_code=500,
                detail="Ã‰chec du scraping - Impossible de rÃ©cupÃ©rer les donnÃ©es"
            )
        
        # Ajouter les flags
        hotel_data["isClient"] = request.isClient
        hotel_data["isMonitored"] = request.isMonitored
        
        # Enregistrer dans Supabase
        created_hotel = supabase_client.create_hotel(hotel_data)
        
        if not created_hotel:
            raise HTTPException(
                status_code=500,
                detail="Ã‰chec de l'enregistrement dans la base de donnÃ©es"
            )
        
        return ScrapeHotelResponse(
            success=True,
            message=f"HÃ´tel '{hotel_data['name']}' ajoutÃ© avec succÃ¨s",
            hotel=created_hotel
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur serveur: {str(e)}"
        )


@app.post("/test-scrape")
async def test_scrape(request: ScrapeHotelRequest):
    """
    Teste le scraping sans enregistrer dans la base
    Utile pour vÃ©rifier qu'une URL fonctionne
    """
    try:
        print(f"\nğŸ§ª Test de scraping: {request.url}")
        
        hotel_data = scrape_hotel_info(request.url)
        
        if not hotel_data:
            return {
                "success": False,
                "message": "Ã‰chec du scraping",
                "data": None
            }
        
        return {
            "success": True,
            "message": "Scraping rÃ©ussi (non enregistrÃ©)",
            "data": hotel_data
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"Erreur: {str(e)}",
            "data": None
        }


class ExtractRequest(BaseModel):
    """Body pour POST /extract (appelÃ© par Next.js)"""
    url: str


@app.post("/extract")
async def extract(request: ExtractRequest):
    """
    Endpoint pour Next.js Â« Ajouter un concurrent Â».
    Body: { "url": "https://www.booking.com/hotel/..." }
    RÃ©ponse: { name, location, stars, photoUrl } (pas d'Ã©criture en base).
    """
    try:
        print(f"\nğŸ” Extract (Next.js): {request.url}")
        # Playwright sync API ne doit pas tourner dans la boucle asyncio â†’ exÃ©cuter en thread
        data = await asyncio.to_thread(scrape_hotel_info, request.url)
        if not data:
            raise HTTPException(
                status_code=500,
                detail="Ã‰chec du scraping - Impossible de rÃ©cupÃ©rer les donnÃ©es"
            )
        # Toujours renvoyer des types attendus par Next (pas de null pour les string)
        return {
            "name": data.get("name") or "",
            "location": data.get("location") or "",
            "stars": data.get("stars") if data.get("stars") is not None else 0,
            "photoUrl": data.get("photoUrl") or "",
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Erreur /extract: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erreur serveur: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   ğŸš€ Booking Scraper API                     â•‘
    â•‘   Serveur dÃ©marrÃ© sur http://{API_HOST}:{API_PORT}  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ğŸ“Œ Endpoints disponibles:
       GET  /               - Info API
       GET  /health         - Health check
       POST /extract        - Extraire infos (Next.js, sans enregistrer)
       POST /scrape-hotel   - Scraper et enregistrer un hÃ´tel
       POST /test-scrape    - Tester le scraping sans enregistrer
    
    ğŸ’¡ Exemple curl:
       curl -X POST http://localhost:8000/scrape-hotel \\
         -H "Content-Type: application/json" \\
         -d '{{"url": "https://www.booking.com/hotel/fr/..."}}'
    """)
    
    uvicorn.run(
        app,
        host=API_HOST,
        port=API_PORT,
        log_level="info"
    )
